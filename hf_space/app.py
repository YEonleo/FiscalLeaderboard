import json
import re
from collections import Counter
from pathlib import Path

import altair as alt
import pandas as pd
import streamlit as st


APP_TITLE = "Fiscal Leaderboard"
PASS_K_OPTIONS = [1, 3, 5]

# Top 10 ì°¨íŠ¸ìš© íŒŒìŠ¤í…” ìƒ‰ìƒ (ì§„í•œ íŒŒìŠ¤í…” í†¤)
TOP10_PASTEL_COLORS = [
    "#5eb8e8", "#6bcb7d", "#e6d84a", "#e8a54b", "#b88dd4",
    "#5eb5a6", "#e8957a", "#9d7bc9", "#6ba3d4", "#8bc34a",
]

# CPA ê³¼ëª© ëª©ë¡
CPA_SUBJECTS = {
    "ì„¸ë²•": "CPA ì„¸ë²•",
    "ê²½ì œì›ë¡ ": "CPA ê²½ì œì›ë¡ ",
    "ê²½ì˜í•™": "CPA ê²½ì˜í•™",
    "íšŒê³„í•™": "CPA íšŒê³„í•™",
    "ìƒë²•": "CPA ìƒë²•",
}

# ê°œì •ì„¸ë²• ì—°ë„ ëª©ë¡ (ì—°ë„ë³„ QA)
TAX_YEARS = [2021, 2022, 2023, 2025]

# ê°œì •ì„¸ë²• ê°ê´€ì‹ 500ë¬¸í•­ ì—°ë„ (tax500)
TAX500_YEARS = [2023, 2024, 2025]


def pass_label(k: int) -> str:
    return f"Pass@{k}"


def find_data_root() -> Path:
    here = Path(__file__).resolve()
    candidates = [here.parent, here.parent.parent, *here.parents]
    for base in candidates:
        if (base / "results_yearly" / "summary").exists() or (
            base / "results_cpa" / "summary"
        ).exists() or (base / "results_tax500" / "summary").exists():
            return base
    return here.parent


def normalize_answer(text: str) -> str:
    if not isinstance(text, str) or not text:
        return ""
    # ê³µë°± ì œê±° (ì¼ë°˜ ê³µë°±, ì¤„ë°”ê¿ˆ, ìœ ë‹ˆì½”ë“œ ê³µë°± \u202f, \u200b ë“±)
    s = text.strip().lower()
    for c in (" ", "\n", "\r", "\t", "\u202f", "\u200b", "\u200c", "\u200d"):
        s = s.replace(c, "")
    # ë§ˆí¬ë‹¤ìš´ ê°•ì¡° ì œê±° (gpt-oss ë“± ëª¨ë¸ ì¶œë ¥ì— ** í¬í•¨ë˜ëŠ” ê²½ìš°)
    s = s.replace("*", "")
    return s


def extract_final_answer(text: str) -> str:
    if not isinstance(text, str) or not text:
        return ""
    if "ìµœì¢…ì •ë‹µ:" in text:
        answer = text.split("ìµœì¢…ì •ë‹µ:")[-1].strip()
        return answer.split("\n")[0].strip()
    return text.strip()


def _answer_match(gt_normalized: str, pred_normalized: str) -> bool:
    if not pred_normalized:
        return False
    if gt_normalized in pred_normalized or pred_normalized in gt_normalized:
        return True
    # ì •ë‹µì´ "~ì…ë‹ˆë‹¤." / "~ì…ë‹ˆë‹¤" í˜•íƒœì¼ ë•Œ, í•µì‹¬ë§Œìœ¼ë¡œë„ ë§¤ì¹­ (gpt-oss ë“± í˜•ì‹ ì°¨ì´ ëŒ€ì‘)
    gt_core = gt_normalized.rstrip(".").removesuffix("ì…ë‹ˆë‹¤").removesuffix("ì…ë‹ˆë‹¤.")
    if gt_core and (gt_core in pred_normalized or pred_normalized in gt_core):
        return True
    return False


def compute_pass_for_row(row: pd.Series, k: int) -> bool:
    gt_normalized = normalize_answer(row.get("ground_truth", ""))
    if not gt_normalized:
        return False
    for i in range(1, k + 1):
        pred_col = f"prediction_{i}"
        pred_text = row.get(pred_col)
        if pred_text is None or pd.isna(pred_text):
            continue
        pred_final = extract_final_answer(pred_text)
        pred_normalized = normalize_answer(pred_final)
        if _answer_match(gt_normalized, pred_normalized):
            return True
    return False


def matching_samples(row: pd.Series, k: int) -> list[int]:
    matches = []
    gt_normalized = normalize_answer(row.get("ground_truth", ""))
    if not gt_normalized:
        return matches
    for i in range(1, k + 1):
        pred_col = f"prediction_{i}"
        pred_text = row.get(pred_col)
        if pred_text is None or pd.isna(pred_text):
            continue
        pred_final = extract_final_answer(pred_text)
        pred_normalized = normalize_answer(pred_final)
        if _answer_match(gt_normalized, pred_normalized):
            matches.append(i)
    return matches


def parse_safe_name(filename: str) -> tuple[str, int | None]:
    base = filename
    if base.endswith("_summary.csv"):
        base = base[: -len("_summary.csv")]
    if base.endswith("_cpa"):
        return base[: -len("_cpa")], None
    parts = base.rsplit("_", 1)
    if len(parts) == 2 and parts[1].isdigit():
        return parts[0], int(parts[1])
    return base, None


def parse_safe_name_raw_evaluated(filename: str) -> tuple[str, int | None]:
    """ì˜ˆ: openai_gpt-oss-120b_2021_raw_evaluated.csv -> (openai_gpt-oss-120b, 2021)"""
    if not filename.endswith("_raw_evaluated.csv"):
        return filename, None
    base = filename[: -len("_raw_evaluated.csv")]
    parts = base.rsplit("_", 1)
    if len(parts) == 2 and parts[1].isdigit():
        return parts[0], int(parts[1])
    return base, None


def parse_safe_name_tax500(filename: str) -> tuple[str, int | None]:
    """ì˜ˆ: Qwen_Qwen2.5-7B-Instruct_tax500_2023_summary.csv -> (Qwen_Qwen2.5-7B-Instruct, 2023)"""
    if not filename.endswith("_summary.csv") or "_tax500_" not in filename:
        return filename, None
    base = filename[: -len("_summary.csv")]
    if "_tax500_" in base:
        head, tail = base.split("_tax500_", 1)
        if tail.isdigit():
            return head, int(tail)
    return base, None


def parse_year(value) -> int | None:
    if value is None or pd.isna(value):
        return None
    text = str(value)
    match = re.search(r"(19|20)\d{2}", text)
    if match:
        return int(match.group(0))
    match = re.search(r"(\d{2})\D*$", text)
    if match:
        yy = int(match.group(1))
        return 2000 + yy if yy <= 30 else 1900 + yy
    return None


@st.cache_data(show_spinner=False)
def load_metadata(data_root: str) -> dict:
    path = Path(data_root) / "model_metadata.json"
    if not path.exists():
        return {"models": []}
    with path.open("r", encoding="utf-8") as f:
        return json.load(f)


def attach_metadata(df: pd.DataFrame, metadata: dict) -> pd.DataFrame:
    if df.empty:
        return df
    models = metadata.get("models", [])
    meta_by_id = {m.get("model_id"): m for m in models}
    meta_by_safe = {m.get("safe_name"): m for m in models}

    def pick(row: pd.Series, key: str):
        meta = meta_by_id.get(row.get("model")) or meta_by_safe.get(row.get("safe_name"))
        return meta.get(key) if meta else None

    df = df.copy()
    for key in [
        "model_id",
        "params_b",
        "params_note",
        "korean_pretrained",
        "organization",
        "note",
        "safe_name",
    ]:
        if key == "model_id":
            df["model_id"] = df.get("model")
            continue
        df[key] = df.apply(lambda r, k=key: pick(r, k), axis=1)

    df["params_b"] = pd.to_numeric(df["params_b"], errors="coerce")
    return df


def _aggregate_raw_evaluated(df_raw: pd.DataFrame) -> pd.DataFrame:
    """raw_evaluated CSV (question_id, sample_id, Judge_Score) -> ë¬¸í•­ë‹¹ 1í–‰, pass_at_1/3/5 from Judge_Score.
    ì£¼ê´€ì‹ ì˜¤ë‹µë¶„ì„ìš©ìœ¼ë¡œ prediction(ëª¨ë¸ë‹µë³€), Judge_Reason(íŒë³„ ì´ìœ ) í¬í•¨."""
    if df_raw.empty or "Judge_Score" not in df_raw.columns:
        return pd.DataFrame()
    # sample_idê°€ ì—†ìœ¼ë©´ 1ë¡œ ê°„ì£¼ (1ìƒ˜í”Œë§Œ ìˆëŠ” ê²½ìš°)
    if "sample_id" not in df_raw.columns:
        df_raw = df_raw.copy()
        df_raw["sample_id"] = 1
    pass_map = df_raw["Judge_Score"].str.strip().str.lower().isin(("pass",))
    df_raw = df_raw.copy()
    df_raw["_is_pass"] = pass_map

    rows = []
    for (qid, model, year), grp in df_raw.groupby(
        ["question_id", "model", "target_year"], dropna=False
    ):
        grp = grp.sort_values("sample_id")
        samples = grp["_is_pass"].tolist()
        pass_at_1 = samples[0] if len(samples) >= 1 else False
        pass_at_3 = any(samples[:3]) if len(samples) >= 3 else any(samples)
        pass_at_5 = any(samples[:5]) if len(samples) >= 5 else any(samples)
        first = grp.iloc[0]
        row = {
            "question_id": qid,
            "model": first["model"],
            "target_year": year,
            "instruction": first.get("instruction", ""),
            "ground_truth": first.get("ground_truth", ""),
            "pass_at_1": bool(pass_at_1),
            "pass_at_3": bool(pass_at_3),
            "pass_at_5": bool(pass_at_5),
        }
        if "prediction" in first.index:
            row["prediction"] = first.get("prediction", "")
        if "Judge_Score" in first.index:
            row["Judge_Score"] = first.get("Judge_Score", "")
        for reason_col in ("Judge_Reason", "Judge_Feedback", "judge_reason", "judge_feedback"):
            if reason_col in first.index and pd.notna(first.get(reason_col)):
                row["Judge_Reason"] = first.get(reason_col, "")
                break
        else:
            row["Judge_Reason"] = ""
        rows.append(row)
    return pd.DataFrame(rows)


@st.cache_data(show_spinner=False)
def load_yearly(data_root: str) -> pd.DataFrame:
    """
    ê°œì •ì„¸ë²•(ì—°ë„ë³„) ë°ì´í„° ë¡œë“œ.
    í‰ê°€ ë°©ì‹: ì˜¤ì§ raw/*_raw_evaluated.csv ì˜ Judge_Score(Pass/Fail) ê¸°ì¤€ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    - results_yearly/raw/*_raw_evaluated.csv ê°€ ìˆëŠ” (ëª¨ë¸, ì—°ë„)ë§Œ ë¦¬ë”ë³´ë“œì— í¬í•¨ë©ë‹ˆë‹¤.
    - summaryëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. (evaluatedê°€ ì—†ëŠ” ëª¨ë¸Â·ì—°ë„ëŠ” ê°œì •ì„¸ë²• ì ìˆ˜ì— í¬í•¨ë˜ì§€ ì•ŠìŒ)
    """
    root = Path(data_root)
    raw_dir = root / "results_yearly" / "raw"
    frames = []

    if not raw_dir.exists():
        return pd.DataFrame()

    for file in sorted(raw_dir.glob("*_raw_evaluated.csv")):
        safe_name, year = parse_safe_name_raw_evaluated(file.name)
        df_raw = pd.read_csv(file)
        agg = _aggregate_raw_evaluated(df_raw)
        if agg.empty:
            continue
        agg["file"] = file.name
        agg["safe_name"] = safe_name
        agg["year_from_file"] = year
        frames.append(agg)

    if not frames:
        return pd.DataFrame()
    df = pd.concat(frames, ignore_index=True)
    if "target_year" in df.columns:
        df["target_year"] = df["target_year"].apply(parse_year)
    return df


@st.cache_data(show_spinner=False)
def load_cpa(data_root: str) -> pd.DataFrame:
    data_dir = Path(data_root) / "results_cpa" / "summary"
    if not data_dir.exists():
        return pd.DataFrame()
    frames = []
    for file in sorted(data_dir.glob("*_summary.csv")):
        df = pd.read_csv(file)
        safe_name, _ = parse_safe_name(file.name)
        df["file"] = file.name
        df["safe_name"] = safe_name
        frames.append(df)
    if not frames:
        return pd.DataFrame()
    df = pd.concat(frames, ignore_index=True)
    if "year" in df.columns:
        df["year"] = df["year"].apply(parse_year)
    for k in PASS_K_OPTIONS:
        col = f"pass_at_{k}"
        if col in df.columns:
            df[col] = df[col].astype(bool)
    return df


@st.cache_data(show_spinner=False)
def load_tax500(data_root: str) -> pd.DataFrame:
    """
    ê°œì •ì„¸ë²• ê°ê´€ì‹ 500ë¬¸í•­(tax500) ê²°ê³¼ ë¡œë“œ.
    results_tax500/summary/*_tax500_*_summary.csv ê¸°ì¤€.
    """
    data_dir = Path(data_root) / "results_tax500" / "summary"
    if not data_dir.exists():
        return pd.DataFrame()
    frames = []
    for file in sorted(data_dir.glob("*_tax500_*_summary.csv")):
        df = pd.read_csv(file)
        safe_name, year_from_file = parse_safe_name_tax500(file.name)
        df["file"] = file.name
        df["safe_name"] = safe_name
        if "target_year" not in df.columns and year_from_file is not None:
            df["target_year"] = year_from_file
        df["target_year"] = df["target_year"].apply(parse_year)
        # pass_at_3ì´ ì—†ìœ¼ë©´ extracted_1~3 vs ground_truthë¡œ ê³„ì‚°
        if "pass_at_3" not in df.columns:
            gt = df["ground_truth"].astype(str).str.strip().str.upper()
            e1 = df.get("extracted_1", pd.Series([""] * len(df))).astype(str).str.strip().str.upper()
            e2 = df.get("extracted_2", pd.Series([""] * len(df))).astype(str).str.strip().str.upper()
            e3 = df.get("extracted_3", pd.Series([""] * len(df))).astype(str).str.strip().str.upper()
            df["pass_at_3"] = (e1 == gt) | (e2 == gt) | (e3 == gt)
        frames.append(df)
    if not frames:
        return pd.DataFrame()
    df = pd.concat(frames, ignore_index=True)
    for k in PASS_K_OPTIONS:
        col = f"pass_at_{k}"
        if col in df.columns:
            df[col] = df[col].astype(bool)
    return df


def shorten(text: str, limit: int = 140) -> str:
    if not isinstance(text, str):
        return ""
    if len(text) <= limit:
        return text
    return text[:limit].rstrip() + "..."


STOPWORDS = {
    "the",
    "and",
    "for",
    "that",
    "this",
    "with",
    "from",
    "you",
    "are",
    "but",
    "ë˜í•œ",
    "ê·¸ë¦¬ê³ ",
    "ë˜ëŠ”",
    "ìˆë‹¤",
    "ì—†ë‹¤",
    "í•œë‹¤",
    "í•©ë‹ˆë‹¤",
    "ê²½ìš°",
    "ëŒ€í•œ",
    "ê´€ë ¨",
    "í•´ë‹¹",
    "ì •ë‹µ",
    "ë‹µ",
}


def top_keywords(texts: list[str], top_n: int = 15) -> pd.DataFrame:
    counter = Counter()
    for text in texts:
        if not isinstance(text, str):
            continue
        tokens = re.findall(r"[A-Za-z]+|[0-9]+|[ê°€-í£]+", text)
        for token in tokens:
            t = token.lower()
            if t in STOPWORDS or len(t) < 2:
                continue
            if t.isdigit():
                continue
            counter[t] += 1
    if not counter:
        return pd.DataFrame(columns=["keyword", "count"])
    data = counter.most_common(top_n)
    return pd.DataFrame(data, columns=["keyword", "count"])


def styled_table(df: pd.DataFrame) -> pd.DataFrame:
    if "pass_rate" in df.columns:
        df = df.copy()
        df["pass_rate"] = df["pass_rate"].round(2)
    return df


def render_metric_cards(title: str, items: list[tuple[str, str]]):
    st.markdown(f"**{title}**")
    cards = ["<div class='metric-grid'>"]
    for label, value in items:
        cards.append(
            "<div class='metric-card'>"
            f"<div class='metric-label'>{label}</div>"
            f"<div class='metric-value'>{value}</div>"
            "</div>"
        )
    cards.append("</div>")
    st.markdown("".join(cards), unsafe_allow_html=True)


def render_aihub_shell():
    st.markdown(
        """
        <div class="info-notice">
            <span class="notice-icon">â„¹ï¸</span>
            <span class="notice-text">
                Fiscal LeaderboardëŠ” ê°œì •ì„¸ë²•(ì—°ë„ë³„ QAÂ·<strong>ê°œì •ì„¸ë²• ê°ê´€ì‹ 500ë¬¸í•­</strong>) ë° CPA ì‹œí—˜ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ 
                í•œêµ­ì–´ LLMì˜ ì„¸ë²•Â·íšŒê³„ ì „ë¬¸ ì§€ì‹ ìˆ˜ì¤€ì„ í‰ê°€í•˜ëŠ” ë²¤ì¹˜ë§ˆí¬ í”Œë«í¼ì…ë‹ˆë‹¤.
            </span>
        </div>
        """,
        unsafe_allow_html=True,
    )


def render_top_model_cards(leaderboard: pd.DataFrame, pass_k: int, top_n: int = 5):
    if leaderboard.empty:
        return
    top_df = leaderboard.head(top_n).copy()
    palette = [
        "#38bdf8",
        "#a3e635",
        "#facc15",
        "#fb7185",
        "#a78bfa",
        "#22c55e",
        "#f97316",
        "#60a5fa",
    ]
    cards = ["<div class='model-grid'>"]
    for i, (_, row) in enumerate(top_df.iterrows()):
        rank = int(row.get("rank", 0))
        score = row.get(f"pass_rate_{pass_k}", row.get("score", 0))
        if pd.isna(score):
            score = 0.0
        model = row.get("display_model", "")
        org = row.get("organization") or "-"
        params = row.get("params_note") or row.get("params_b") or "-"
        p1 = row.get("pass_rate_1")
        p3 = row.get("pass_rate_3")
        p5 = row.get("pass_rate_5")
        accent = palette[i % len(palette)]
        chips = []
        if pd.notna(p1):
            chips.append(
                f"<span class='stat-chip' style='--chip:#e0f2fe;'>P@1 {p1:.3f}</span>"
            )
        if pd.notna(p3):
            chips.append(
                f"<span class='stat-chip' style='--chip:#fef9c3;'>P@3 {p3:.3f}</span>"
            )
        if pd.notna(p5):
            chips.append(
                f"<span class='stat-chip' style='--chip:#ffe4e6;'>P@5 {p5:.3f}</span>"
            )
        chips_html = "".join(chips)
        cards.append(
            f"<div class='model-card' style='--accent: {accent};'>"
            f"<div class='model-rank'>Rank {rank}</div>"
            f"<div class='model-name'>{model}</div>"
            f"<div class='metric-value'>{score:.3f}</div>"
            f"<div class='stat-row'>{chips_html}</div>"
            f"<div class='model-meta'>í”Œë«í¼: {org}</div>"
            f"<div class='model-meta'>íŒŒë¼ë¯¸í„°: {params}</div>"
            "</div>"
        )
    cards.append("</div>")
    st.markdown("".join(cards), unsafe_allow_html=True)


def render_header():
    st.markdown(
        """
        <style>
        @import url('https://cdn.jsdelivr.net/gh/orioncactus/pretendard@v1.3.9/dist/web/static/pretendard.css');
        
        /* ê¸°ë³¸ í°íŠ¸: Pretendard Bold */
        html, body, [class*="css"] {
            font-family: "Pretendard", "Pretendard Variable", -apple-system, BlinkMacSystemFont, sans-serif;
            font-weight: 700;
            color: #1a1a1a;
        }
        
        /* ì „ì²´ ë°°ê²½ ë° ë©”ì¸ ìŠ¤í¬ë¡¤ ì˜ì—­ ì¤‘ì•™ ì •ë ¬ */
        [data-testid="stAppViewContainer"] {
            background: #f8f9fa;
        }
        [data-testid="stAppViewContainer"] > section > div {
            max-width: 100%;
            margin-left: auto;
            margin-right: auto;
        }
        
        /* ë©”ì¸ ì»¨í…Œì´ë„ˆ - ê°€ë¡œ í­ ì œí•œ, ì¤‘ì•™ ì •ë ¬ */
        .block-container {
            padding: 2rem 2rem 3rem 2rem;
            max-width: 1100px;
            margin-left: auto;
            margin-right: auto;
            width: 100%;
            box-sizing: border-box;
        }
        /* Top 10 / ë¦¬ë”ë³´ë“œ ì˜ì—­: ì»¬ëŸ¼ í–‰ ì¤‘ì•™ ì •ë ¬ */
        [data-testid="stHorizontalBlock"] {
            display: flex;
            justify-content: center;
            align-items: stretch;
            gap: 1rem;
            flex-wrap: wrap;
        }
        [data-testid="stHorizontalBlock"] [data-testid="column"] {
            min-width: 0;
        }
        /* ì°¨íŠ¸ 2ì—´ í–‰: ê° ì»¬ëŸ¼ ìµœëŒ€ ë„ˆë¹„ ì œí•œí•´ ë¸”ë¡ ì „ì²´ê°€ ì¤‘ì•™ì— ì˜¤ë„ë¡ */
        [data-testid="stHorizontalBlock"]:has(div[data-testid="stVegaLiteChart"]) [data-testid="column"] {
            flex: 0 1 420px;
            max-width: 100%;
        }
        /* ì°¨íŠ¸ ì»¨í…Œì´ë„ˆ ìì²´ë„ ì¤‘ì•™ ì •ë ¬ */
        div[data-testid="stVegaLiteChart"] {
            margin-left: auto;
            margin-right: auto;
        }
        
        /* Hero ì„¹ì…˜ - AIí—ˆë¸Œ ìŠ¤íƒ€ì¼ */
        .hero {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 2.5rem 2rem;
            border-radius: 16px;
            margin-bottom: 2rem;
            box-shadow: 0 4px 20px rgba(102, 126, 234, 0.25);
        }
        .hero h1 {
            color: #ffffff;
            font-size: 2.2rem;
            font-weight: 700;
            margin: 0 0 0.5rem 0;
            letter-spacing: -0.02em;
        }
        .hero p {
            color: rgba(255, 255, 255, 0.9);
            font-size: 1.05rem;
            margin: 0;
            line-height: 1.6;
        }
        
        /* ë„¤ë¹„ê²Œì´ì…˜ - AIí—ˆë¸Œ ìŠ¤íƒ€ì¼ */
        .aihub-nav {
            background: #ffffff;
            border-radius: 12px;
            padding: 0.8rem 1.2rem;
            margin-bottom: 1rem;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.08);
        }
        .nav-links {
            display: flex;
            gap: 0.5rem;
            flex-wrap: wrap;
        }
        .nav-link {
            text-decoration: none;
            padding: 0.5rem 1.2rem;
            border-radius: 8px;
            color: #495057;
            background: #f8f9fa;
            font-size: 0.95rem;
            font-weight: 500;
            transition: all 0.2s ease;
            border: 1px solid #e9ecef;
        }
        .nav-link.active {
            background: #667eea;
            color: #ffffff;
            border-color: #667eea;
            font-weight: 600;
        }
        .nav-link:hover {
            background: #e9ecef;
        }
        .nav-link.active:hover {
            background: #5568d3;
        }
        
        /* ì•Œë¦¼ ë°•ìŠ¤ */
        .info-notice {
            background: #e3f2fd;
            border-left: 4px solid #2196f3;
            padding: 1rem 1.2rem;
            border-radius: 8px;
            margin-bottom: 1.5rem;
            display: flex;
            align-items: flex-start;
            gap: 0.8rem;
        }
        .notice-icon {
            font-size: 1.2rem;
            flex-shrink: 0;
        }
        .notice-text {
            color: #1565c0;
            font-size: 0.95rem;
            line-height: 1.6;
        }
        
        /* ë©”íŠ¸ë¦­ ì¹´ë“œ */
        div[data-testid="stMetric"] {
            background: #ffffff;
            padding: 1.2rem 1.4rem;
            border-radius: 12px;
            border: 1px solid #e9ecef;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.06);
            transition: transform 0.2s ease, box-shadow 0.2s ease;
        }
        div[data-testid="stMetric"]:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
        }
        div[data-testid="stMetric"] label {
            font-size: 0.85rem !important;
            color: #6c757d !important;
            font-weight: 500 !important;
        }
        div[data-testid="stMetric"] [data-testid="stMetricValue"] {
            font-size: 1.8rem !important;
            color: #667eea !important;
            font-weight: 700 !important;
        }
        
        /* ì°¨íŠ¸ ì»¨í…Œì´ë„ˆ - ë¸”ë¡ ì¹¨ë²” ë°©ì§€, yì¶• ê³µê°„ ìƒì‡„ë¡œ ì‹œê°ì  ì¤‘ì•™ ì •ë ¬ */
        div[data-testid="stVegaLiteChart"] {
            background: #ffffff;
            border-radius: 12px;
            border: 1px solid #e9ecef;
            padding: 1rem 1.25rem 1rem 1rem;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.06);
            max-width: 100%;
            overflow: hidden;
            box-sizing: border-box;
        }
        div[data-testid="stVegaLiteChart"] > div {
            max-width: 100% !important;
            overflow: hidden !important;
        }
        div[data-testid="stVegaLiteChart"] svg {
            max-width: 100% !important;
            height: auto !important;
        }
        /* ì»¬ëŸ¼ ë‚´ ì°¨íŠ¸ ë˜í¼ */
        [data-testid="column"] div[data-testid="stVegaLiteChart"] {
            width: 100%;
        }
        
        /* ë°ì´í„°í”„ë ˆì„ */
        div[data-testid="stDataFrame"] {
            background: #ffffff;
            border-radius: 12px;
            border: 1px solid #e9ecef;
            padding: 0.5rem;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.06);
        }
        
        /* ì„¹ì…˜ í—¤ë” - ì¤‘ì•™ ì •ë ¬ */
        h3 {
            color: #2d3436;
            font-weight: 700;
            margin-top: 2rem;
            margin-bottom: 1rem;
            font-size: 1.4rem;
            text-align: center;
        }
        
        /* ìº¡ì…˜ */
        .caption, [data-testid="stCaptionContainer"] {
            color: #6c757d;
            font-size: 0.85rem;
            line-height: 1.5;
        }
        
        /* ì…ë ¥ í•„ë“œ */
        input[type="text"] {
            border-radius: 8px !important;
            border: 1px solid #dee2e6 !important;
            padding: 0.6rem 1rem !important;
        }
        input[type="text"]:focus {
            border-color: #667eea !important;
            box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.1) !important;
        }
        
        /* íƒ­ */
        .stTabs [data-baseweb="tab-list"] {
            gap: 0.5rem;
            background: #f8f9fa;
            border-radius: 10px;
            padding: 0.3rem;
        }
        .stTabs [data-baseweb="tab"] {
            border-radius: 8px;
            padding: 0.6rem 1.5rem;
            font-weight: 500;
        }
        .stTabs [aria-selected="true"] {
            background: #ffffff;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.08);
        }
        
        /* ì»¬ëŸ¼ ë‚´ ì½˜í…ì¸  ì˜¤ë²„í”Œë¡œìš° ë°©ì§€ */
        [data-testid="column"] {
            min-width: 0;
            overflow: hidden;
        }
        [data-testid="column"] > div {
            max-width: 100%;
            min-width: 0;
        }
        
        /* ë°˜ì‘í˜• - í° í™”ë©´ì—ì„œë„ ê°€ë¡œ ì œí•œ ìœ ì§€ */
        @media (min-width: 1400px) {
            .block-container {
                max-width: 1200px;
            }
        }
        </style>
        <div class="hero">
            <h1>ğŸ›ï¸ Fiscal Leaderboard</h1>
            <p>í•œêµ­ì–´ LLMì˜ ì„¸ë²• ë° íšŒê³„ ì „ë¬¸ ì§€ì‹ì„ í‰ê°€í•˜ëŠ” ë²¤ì¹˜ë§ˆí¬ í”Œë«í¼</p>
        </div>
        """,
        unsafe_allow_html=True,
    )


def build_leaderboard(df: pd.DataFrame, pass_k: int) -> pd.DataFrame:
    pass_col = f"pass_at_{pass_k}"
    if df.empty or pass_col not in df.columns:
        return pd.DataFrame()
    grouped = build_leaderboard_all(df)
    if grouped.empty:
        return grouped
    pass_rate_col = f"pass_rate_{pass_k}"
    grouped["pass_rate"] = grouped[pass_rate_col] * 100
    grouped["display_model"] = grouped["model"].fillna(grouped["safe_name"])
    grouped = grouped.sort_values("pass_rate", ascending=False)
    return grouped


def build_leaderboard_all(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty:
        return pd.DataFrame()
    agg_dict = dict(
        questions=("question_id", "count"),
        params_b=("params_b", "first"),
        params_note=("params_note", "first"),
        organization=("organization", "first"),
        korean_pretrained=("korean_pretrained", "first"),
        note=("note", "first"),
        safe_name=("safe_name", "first"),
    )
    for k in PASS_K_OPTIONS:
        col = f"pass_at_{k}"
        if col in df.columns:
            agg_dict[f"pass_rate_{k}"] = (col, "mean")
    grouped = df.groupby("model", dropna=False).agg(**agg_dict).reset_index()
    return grouped


def metric_series(df: pd.DataFrame, pass_k: int, **filters) -> pd.Series:
    subset = df
    for key, value in filters.items():
        subset = subset[subset[key] == value]
    if subset.empty:
        return pd.Series(dtype=float)
    return subset.groupby("model")[f"pass_at_{pass_k}"].mean()


def build_metric_table(
    yearly_df: pd.DataFrame,
    cpa_df: pd.DataFrame,
    tax500_df: pd.DataFrame,
    metadata: dict,
    pass_k: int,
    include_yearly_tax: bool = False,
) -> pd.DataFrame:
    metrics = {}

    tax_year_cols = []
    tax500_year_cols = []
    cpa_year_cols = []
    cpa_subject_cols = []

    # ì˜µì…˜ ì‹œ ê°œì •ì„¸ë²•(ì£¼ê´€ì‹Â·ì—°ë„ë³„) í¬í•¨
    if include_yearly_tax and not yearly_df.empty:
        metrics["ê°œì •ì„¸ë²• ì¢…í•©"] = metric_series(yearly_df, pass_k)
        for year in sorted(yearly_df["target_year"].dropna().unique()):
            col = f"ê°œì •ì„¸ë²•_{int(year)}"
            metrics[col] = metric_series(yearly_df, pass_k, target_year=year)
            tax_year_cols.append(col)

    if not tax500_df.empty:
        metrics["ê°œì •ì„¸ë²• ê°ê´€ì‹ ì¢…í•©"] = metric_series(tax500_df, pass_k)
        for year in sorted(tax500_df["target_year"].dropna().unique()):
            col = f"ê°œì •ì„¸ë²• ê°ê´€ì‹_{int(year)}"
            metrics[col] = metric_series(tax500_df, pass_k, target_year=year)
            tax500_year_cols.append(col)

    if not cpa_df.empty:
        metrics["CPA ì¢…í•©"] = metric_series(cpa_df, pass_k)
        for year in sorted(cpa_df["year"].dropna().unique()):
            col = f"CPA_{int(year)}"
            metrics[col] = metric_series(cpa_df, pass_k, year=year)
            cpa_year_cols.append(col)
        for subject in sorted(cpa_df["subject"].dropna().unique()):
            col = f"CPA_{subject}"
            metrics[col] = metric_series(cpa_df, pass_k, subject=subject)
            cpa_subject_cols.append(col)

    if not metrics:
        return pd.DataFrame()

    metric_df = pd.concat(metrics, axis=1)
    metric_df.index.name = "model"
    metric_df = metric_df.reset_index()

    meta_cols = [
        "model",
        "safe_name",
        "organization",
        "params_b",
        "params_note",
        "korean_pretrained",
    ]
    base_parts = []
    if not yearly_df.empty:
        b = yearly_df[[c for c in meta_cols if c in yearly_df.columns]].drop_duplicates()
        for c in meta_cols:
            if c not in b.columns:
                b[c] = None
        base_parts.append(b)
    if not cpa_df.empty:
        b = cpa_df[[c for c in meta_cols if c in cpa_df.columns]].drop_duplicates()
        for c in meta_cols:
            if c not in b.columns:
                b[c] = None
        base_parts.append(b)
    if not tax500_df.empty:
        t5 = tax500_df[["model", "safe_name"]].drop_duplicates()
        for c in meta_cols:
            if c not in t5.columns:
                t5[c] = None
        base_parts.append(t5)
    base = pd.concat(base_parts, ignore_index=True) if base_parts else pd.DataFrame()
    if base.empty:
        return pd.DataFrame()
    base = base.dropna(subset=["model"]).drop_duplicates(subset=["model"])
    base = attach_metadata(base, metadata)
    base = (
        base.groupby("model", dropna=False)
        .agg(
            safe_name=("safe_name", "first"),
            organization=("organization", "first"),
            params_b=("params_b", "first"),
            params_note=("params_note", "first"),
            korean_pretrained=("korean_pretrained", "first"),
        )
        .reset_index()
    )

    metric_df = metric_df.merge(base, on="model", how="left")
    metric_df["display_model"] = metric_df["model"].fillna(metric_df["safe_name"])

    # ì „ì²´ ëª¨ë¸ ì„±ëŠ¥ ì¢…í•©: ê°€ì¤‘ í‰ê· . None/NaNì€ 0ì . (ê°ê´€ì‹ 0.6ë°°, ì£¼ê´€ì‹ í¬í•¨ ì‹œ 1.0ë°°)
    WEIGHT_CPA = 1.0
    WEIGHT_TAX500 = 0.6
    WEIGHT_YEARLY = 1.0
    numer = pd.Series(0.0, index=metric_df.index)
    total_weight = 0.0
    if "CPA ì¢…í•©" in metric_df.columns:
        numer = numer + metric_df["CPA ì¢…í•©"].fillna(0) * WEIGHT_CPA
        total_weight += WEIGHT_CPA
    if "ê°œì •ì„¸ë²• ê°ê´€ì‹ ì¢…í•©" in metric_df.columns:
        numer = numer + metric_df["ê°œì •ì„¸ë²• ê°ê´€ì‹ ì¢…í•©"].fillna(0) * WEIGHT_TAX500
        total_weight += WEIGHT_TAX500
    if include_yearly_tax and "ê°œì •ì„¸ë²• ì¢…í•©" in metric_df.columns:
        numer = numer + metric_df["ê°œì •ì„¸ë²• ì¢…í•©"].fillna(0) * WEIGHT_YEARLY
        total_weight += WEIGHT_YEARLY
    metric_df["ì „ì²´ ëª¨ë¸ ì„±ëŠ¥ ì¢…í•©"] = (
        numer / total_weight if total_weight > 0 else pd.Series(float("nan"), index=metric_df.index)
    )

    metric_order = []
    for col in ["ì „ì²´ ëª¨ë¸ ì„±ëŠ¥ ì¢…í•©", "CPA ì¢…í•©", "ê°œì •ì„¸ë²• ì¢…í•©", "ê°œì •ì„¸ë²• ê°ê´€ì‹ ì¢…í•©"]:
        if col in metric_df.columns:
            metric_order.append(col)
    metric_order.extend(tax_year_cols)
    metric_order.extend(tax500_year_cols)
    metric_order.extend(cpa_year_cols)
    metric_order.extend(cpa_subject_cols)
    metric_df.attrs["metric_order"] = metric_order
    return metric_df


def pass_heatmap(df: pd.DataFrame, pass_k: int) -> pd.DataFrame:
    pass_col = f"pass_at_{pass_k}"
    if df.empty or pass_col not in df.columns:
        return pd.DataFrame()
    return (
        df.groupby(["model", "target_year"], dropna=False)[pass_col]
        .mean()
        .reset_index()
        .assign(pass_rate=lambda d: d[pass_col] * 100)
    )


def make_top10_chart(
    df: pd.DataFrame, pass_k: int, title: str, height: int = 220
) -> alt.Chart | None:
    leaderboard = build_leaderboard(df, pass_k)
    if leaderboard.empty:
        return None
    top_df = leaderboard.head(10).copy()
    top_df["score"] = top_df["pass_rate"] / 100
    top_df["label"] = top_df["display_model"].apply(
        lambda x: (x[:12] + "â€¦") if isinstance(x, str) and len(x) > 13 else x
    )
    # íˆ´íŒ ì²« ì¤„ì— í•„ë“œëª… ì—†ì´ ëª¨ë¸ëª…ë§Œ ë³´ì´ê²Œ (ì œë¡œí­ ìŠ¤í˜ì´ìŠ¤ ì»¬ëŸ¼ ì‚¬ìš©)
    _z = "\u200b"
    top_df[_z] = top_df["display_model"]
    hover = alt.selection_point(fields=["display_model"], on="mouseover", empty="none")
    bars = (
        alt.Chart(top_df)
        .mark_bar(cornerRadiusTopLeft=6, cornerRadiusTopRight=6)
        .encode(
            x=alt.X(
                "label:N",
                sort="-y",
                title="",
                scale=alt.Scale(paddingInner=0.28),
                axis=alt.Axis(
                    labelAngle=-25,
                    labelLimit=90,
                    labelFontSize=10,
                    labelColor="#000000",
                    labelFontWeight="bold",
                ),
            ),
            y=alt.Y("score:Q", title="", scale=alt.Scale(domain=[0, 1])),
            color=alt.Color(
                "display_model:N",
                legend=None,
                scale=alt.Scale(range=TOP10_PASTEL_COLORS),
            ),
            opacity=alt.condition(hover, alt.value(1.0), alt.value(0.7)),
            tooltip=[
                alt.Tooltip(f"{_z}:N", title=""),
                alt.Tooltip("score:Q", format=".3f", title="ì ìˆ˜"),
            ],
        )
        .add_params(hover)
    )
    text = (
        alt.Chart(top_df)
        .mark_text(dy=-6, color="#374151", fontSize=11, align="center")
        .encode(
            x=alt.X("label:N", sort="-y"),
            y=alt.Y("score:Q"),
            text=alt.Text("score:Q", format=".3f"),
        )
    )
    chart = (bars + text).properties(
        height=height,
        width=400,
        title=title,
        padding={"left": 10, "right": 42, "top": 10, "bottom": 10},
    )
    return (
        chart.configure_axis(gridOpacity=0.4, gridDash=[2, 2])
        .configure_view(strokeWidth=0)
        .configure_title(align="center", anchor="middle")
    )


def make_metric_top10_chart(
    metric_df: pd.DataFrame, metric_col: str, title: str, height: int = 300
) -> alt.Chart | None:
    if metric_df.empty or metric_col not in metric_df.columns:
        return None
    df = metric_df[["display_model", metric_col]].dropna()
    if df.empty:
        return None
    df = df.sort_values(metric_col, ascending=False).head(10).copy()
    df["score"] = df[metric_col]
    
    def smart_label(name: str) -> str:
        """ëª¨ë¸ëª…ì„ ê°„ê²°í•˜ê²Œ í‘œì‹œí•˜ë˜ êµ¬ë¶„ ê°€ëŠ¥í•˜ê²Œ"""
        if not isinstance(name, str):
            return ""
        # ì „ì²´ ëª¨ë¸ ID ì‚¬ìš©
        parts = name.split("/")
        if len(parts) == 2:
            # org/model í˜•íƒœ
            org, model_name = parts
            # ëª¨ë¸ëª…ì—ì„œ ì£¼ìš” ì •ë³´ ì¶”ì¶œ
            if "Qwen" in model_name:
                # Qwen2.5-7B, Qwen3-8B ë“± ë²„ì „ê³¼ í¬ê¸° ëª¨ë‘ í‘œì‹œ
                match = re.search(r"(Qwen\d+(?:\.\d+)?)-?(\d+\.?\d*B)", model_name)
                if match:
                    return f"{match.group(1)} {match.group(2)}"
                return model_name[:20]
            elif "EXAONE" in model_name:
                # EXAONE-4.0-32B í˜•íƒœ
                match = re.search(r"(EXAONE-[\d.]+)-?(\d+\.?\d*B)", model_name)
                if match:
                    return f"{match.group(1)} {match.group(2)}"
                return model_name[:20]
            else:
                # ê¸°íƒ€ ëª¨ë¸
                return model_name[:18]
        else:
            # orgê°€ ì—†ëŠ” ê²½ìš°
            return name[:18]
    
    df["label"] = df["display_model"].apply(smart_label)
    # íˆ´íŒ ì²« ì¤„ì— í•„ë“œëª… ì—†ì´ ëª¨ë¸ëª…ë§Œ ë³´ì´ê²Œ (ì œë¡œí­ ìŠ¤í˜ì´ìŠ¤ ì»¬ëŸ¼ ì‚¬ìš©)
    _z = "\u200b"
    df[_z] = df["display_model"]
    hover = alt.selection_point(fields=["display_model"], on="mouseover", empty="none")
    bars = (
        alt.Chart(df)
        .mark_bar(cornerRadiusTopLeft=6, cornerRadiusTopRight=6)
        .encode(
            x=alt.X(
                "label:N",
                sort="-y",
                title="",
                scale=alt.Scale(paddingInner=0.28),
                axis=alt.Axis(
                    labelAngle=-35,
                    labelLimit=140,
                    labelFontSize=9.5,
                    labelOverlap=False,
                    labelColor="#000000",
                    labelFontWeight="bold",
                ),
            ),
            y=alt.Y("score:Q", title="", scale=alt.Scale(domain=[0, 1])),
            color=alt.Color(
                "display_model:N",
                legend=None,
                scale=alt.Scale(range=TOP10_PASTEL_COLORS),
            ),
            opacity=alt.condition(hover, alt.value(1.0), alt.value(0.7)),
            tooltip=[
                alt.Tooltip(f"{_z}:N", title=""),
                alt.Tooltip("score:Q", format=".3f", title="ì ìˆ˜"),
            ],
        )
        .add_params(hover)
    )
    text = (
        alt.Chart(df)
        .mark_text(dy=-6, color="#374151", fontSize=11, align="center")
        .encode(
            x=alt.X("label:N", sort="-y"),
            y=alt.Y("score:Q"),
            text=alt.Text("score:Q", format=".3f"),
        )
    )
    chart_width = 380
    # yì¶• ë ˆì´ë¸”ì´ ì™¼ìª½ ê³µê°„ì„ ì°¨ì§€í•˜ë¯€ë¡œ ì˜¤ë¥¸ìª½ íŒ¨ë”©ì„ ë„‰ë„‰íˆ í•´ì„œ ì‹œê°ì  ì¤‘ì•™ ì •ë ¬
    chart = (bars + text).properties(
        height=height,
        width=chart_width,
        title=title,
        padding={"left": 10, "right": 42, "top": 10, "bottom": 10},
    )
    return (
        chart.configure_axis(gridOpacity=0.4, gridDash=[2, 2])
        .configure_view(strokeWidth=0)
        .configure_title(align="center", anchor="middle")
    )


def render_leaderboard_section(
    yearly_df: pd.DataFrame,
    cpa_df: pd.DataFrame,
    tax500_df: pd.DataFrame,
    pass_k: int,
    metadata: dict,
    include_yearly_tax: bool = False,
):
    metric_table = build_metric_table(
        yearly_df, cpa_df, tax500_df, metadata, pass_k, include_yearly_tax
    )
    if metric_table.empty:
        st.info("í‘œì‹œí•  ë¦¬ë”ë³´ë“œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    metric_order = metric_table.attrs.get("metric_order", [])
    primary_metric = (
        "ì „ì²´ ëª¨ë¸ ì„±ëŠ¥ ì¢…í•©"
        if "ì „ì²´ ëª¨ë¸ ì„±ëŠ¥ ì¢…í•©" in metric_table.columns
        else (metric_order[0] if metric_order else None)
    )

    if not primary_metric:
        st.warning("í‰ê°€ ì§€í‘œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    table_sorted = metric_table.sort_values(primary_metric, ascending=False)
    table_sorted["rank"] = range(1, len(table_sorted) + 1)
    top_model = table_sorted.iloc[0]
    avg_score = table_sorted[primary_metric].mean()
    total_models = table_sorted.shape[0]
    total_questions = int(len(yearly_df) + len(cpa_df) + len(tax500_df))

    # ìƒë‹¨ í†µê³„ ì¹´ë“œ
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("ëª¨ë¸ ìˆ˜", f"{total_models}")
    col2.metric("ë¬¸í•­ ìˆ˜", f"{total_questions:,}")
    col3.metric("í‰ê·  ì ìˆ˜", f"{avg_score:.3f}")
    col4.metric("Top Model", f"{top_model['display_model']}")

    # Top 10 ì°¨íŠ¸ ì„¹ì…˜
    st.markdown("### ğŸ“Š Top 10 ëª¨ë¸")
    chart_height = st.session_state.get("lb_chart_height", 300)

    main_metrics = [
        col
        for col in [
            "ì „ì²´ ëª¨ë¸ ì„±ëŠ¥ ì¢…í•©",
            "CPA ì¢…í•©",
            "ê°œì •ì„¸ë²• ì¢…í•©",
            "ê°œì •ì„¸ë²• ê°ê´€ì‹ ì¢…í•©",
        ]
        if col in metric_table.columns
    ]
    metric_charts = []
    for col in main_metrics:
        chart = make_metric_top10_chart(
            table_sorted, col, col, height=chart_height
        )
        if chart:
            metric_charts.append(chart)

    # 2ì—´ë¡œ ì°¨íŠ¸ ë°°ì¹˜ (ì°¨íŠ¸ê°€ 1ê°œì—¬ë„ ë°˜ì¹¸ë§Œ ì°¨ì§€)
    if metric_charts:
        for i in range(0, len(metric_charts), 2):
            cols = st.columns(2)
            if i + 1 < len(metric_charts):
                with cols[0]:
                    st.altair_chart(metric_charts[i], width="stretch")
                with cols[1]:
                    st.altair_chart(metric_charts[i + 1], width="stretch")
            else:
                # ì°¨íŠ¸ê°€ 1ê°œë§Œ ìˆì–´ë„ ì™¼ìª½ ë°˜ì¹¸ë§Œ ì°¨ì§€
                with cols[0]:
                    st.altair_chart(metric_charts[i], width="stretch")

    # ë¦¬ë”ë³´ë“œ í…Œì´ë¸” (í–‰ hover ì‹œ íšŒìƒ‰ ìŒì˜)
    st.markdown("### ğŸ“‹ ì „ì²´ ë¦¬ë”ë³´ë“œ")
    st.markdown(
        """
        <style>
        div[data-testid="stDataFrame"] tbody tr:hover {
            background-color: #eef0f2 !important;
        }
        div[data-testid="stDataFrame"] tbody tr {
            transition: background-color 0.15s ease;
        }
        </style>
        """,
        unsafe_allow_html=True,
    )
    table_search = st.text_input(
        "ğŸ” ëª¨ë¸ ê²€ìƒ‰", 
        key="table_search", 
        placeholder="ëª¨ë¸ëª…ìœ¼ë¡œ ê²€ìƒ‰í•˜ì„¸ìš”"
    )

    table_df = table_sorted.copy()
    if table_search:
        mask = table_df["display_model"].str.contains(
            table_search, case=False, na=False
        )
        table_df = table_df[mask]

    # í…Œì´ë¸” ì»¬ëŸ¼ êµ¬ì„±: ìˆœìœ„, ëª¨ë¸ëª…, ê° ì„¸ë¶€ ì ìˆ˜
    table_display = table_df.copy()
    table_display["ìˆœìœ„"] = range(1, len(table_display) + 1)
    table_display["ëª¨ë¸ëª…"] = table_display["display_model"]
    
    # í…Œì´ë¸” ì»¬ëŸ¼: ìˆœìœ„, ëª¨ë¸ëª…, ì„¸ë¶€ ì ìˆ˜ë“¤
    table_cols = ["ìˆœìœ„", "ëª¨ë¸ëª…"]
    for col in metric_order:
        if col in table_display:
            table_display[col] = (table_display[col] * 100).round(1)  # ë°±ë¶„ìœ¨ë¡œ í‘œì‹œ
            table_cols.append(col)
    
    # ì ìˆ˜ê°€ ìˆëŠ” í–‰ë§Œ í‘œì‹œ
    display_df = table_display[table_cols].dropna(subset=[c for c in table_cols if c not in ["ìˆœìœ„", "ëª¨ë¸ëª…"]], how="all")
    
    st.dataframe(
        display_df, 
        width='stretch',
        height=400,
        hide_index=True
    )
    
    caption_parts = [
        f"ğŸ’¡ ì ìˆ˜ëŠ” ì •í™•ë„(%)ë¡œ í‘œì‹œë©ë‹ˆë‹¤. ì´ {len(display_df)}ê°œ ëª¨ë¸ì´ í‰ê°€ë˜ì—ˆìŠµë‹ˆë‹¤. "
    ]
    if "ê°œì •ì„¸ë²• ì¢…í•©" in metric_table.columns:
        caption_parts.append(
            "ì „ì²´ ëª¨ë¸ ì„±ëŠ¥ ì¢…í•© = CPA(1.0) + ê°œì •ì„¸ë²• ì£¼ê´€ì‹(1.0) + ê°œì •ì„¸ë²• ê°ê´€ì‹(0.6) ê°€ì¤‘ í‰ê· . "
        )
    else:
        caption_parts.append(
            "ì „ì²´ ëª¨ë¸ ì„±ëŠ¥ ì¢…í•© = CPA(1.0) + ê°œì •ì„¸ë²• ê°ê´€ì‹(0.6) ê°€ì¤‘ í‰ê· . "
        )
    caption_parts.append("(ê°ê´€ì‹ì€ GPT ê¸°ë°˜ ë°ì´í„°ë¡œ 0.6ë°° ì ìš©)")
    st.caption("".join(caption_parts))
    
    # ìƒì„¸ ì„¤ì •
    with st.expander("âš™ï¸ ì°¨íŠ¸ ì„¤ì •"):
        st.session_state["lb_chart_height"] = st.slider(
            "Top10 ì°¨íŠ¸ ë†’ì´",
            min_value=220,
            max_value=400,
            value=st.session_state.get("lb_chart_height", 300),
        )


def render_error_section(df: pd.DataFrame, pass_k: int, dataset: str):
    """ì˜¤ë‹µ ë¶„ì„ í˜ì´ì§€"""
    pass_col = f"pass_at_{pass_k}"
    if df.empty or pass_col not in df.columns:
        st.info("ì˜¤ë‹µ ë¶„ì„ì— í•„ìš”í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    model_list = sorted(df["model"].dropna().unique().tolist())
    if not model_list:
        st.info("ì„ íƒ ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    st.markdown("### ğŸ” ì˜¤ë‹µ ë¶„ì„")
    
    # ëª¨ë¸ ì„ íƒ
    model_choice = st.selectbox(
        "ë¶„ì„í•  ëª¨ë¸ ì„ íƒ", 
        model_list,
        format_func=lambda x: x.split('/')[-1] if '/' in x else x
    )
    df_model = df[df["model"] == model_choice].copy()
    if df_model.empty:
        st.info("ì„ íƒí•œ ëª¨ë¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    incorrect = df_model[~df_model[pass_col]]
    correct = df_model[df_model[pass_col]]
    accuracy = (len(correct) / len(df_model) * 100) if len(df_model) > 0 else 0

    # í†µê³„ ì¹´ë“œ
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("ì •ë‹µë¥ ", f"{accuracy:.1f}%")
    col2.metric("ì •ë‹µ ìˆ˜", f"{len(correct):,}ê°œ")
    col3.metric("ì˜¤ë‹µ ìˆ˜", f"{len(incorrect):,}ê°œ")
    col4.metric("ì „ì²´ ë¬¸í•­", f"{len(df_model):,}ê°œ")

    if incorrect.empty:
        st.success("ğŸ‰ ì™„ë²½í•œ ì •ë‹µë¥ ì…ë‹ˆë‹¤!")
        return

    # ê°œì •ì„¸ë²• ê°ê´€ì‹: ë‚œì´ë„ë³„ ì •ë‹µ/ì˜¤ë‹µ (ì˜¤ë‹µ ë¶„ì„ ìƒë‹¨)
    if "difficulty" in df_model.columns and df_model["difficulty"].notna().any():
        st.markdown("#### ğŸ“Š ë‚œì´ë„ë³„ ì •ë‹µÂ·ì˜¤ë‹µ")
        diff_stats = []
        for diff in sorted(df_model["difficulty"].dropna().unique()):
            sub = df_model[df_model["difficulty"] == diff]
            n = len(sub)
            c = sub[pass_col].sum()
            diff_stats.append({
                "ë‚œì´ë„": diff,
                "ë¬¸í•­ ìˆ˜": int(n),
                "ì •ë‹µ ìˆ˜": int(c),
                "ì˜¤ë‹µ ìˆ˜": int(n - c),
                "ì •ë‹µë¥ (%)": round(c / n * 100, 1) if n else 0,
            })
        diff_df = pd.DataFrame(diff_stats)
        col_diff1, col_diff2 = st.columns(2)
        with col_diff1:
            st.dataframe(
                diff_df.set_index("ë‚œì´ë„"),
                use_container_width=True,
                hide_index=True,
            )
        with col_diff2:
            err_by_diff = incorrect["difficulty"].value_counts().reset_index()
            err_by_diff.columns = ["ë‚œì´ë„", "ì˜¤ë‹µìˆ˜"]
            if not err_by_diff.empty:
                diff_chart = (
                    alt.Chart(err_by_diff)
                    .mark_bar(color="#764ba2", cornerRadiusEnd=4)
                    .encode(
                        x=alt.X("ë‚œì´ë„:N", title="ë‚œì´ë„"),
                        y=alt.Y("ì˜¤ë‹µìˆ˜:Q", title="ì˜¤ë‹µ ìˆ˜"),
                        tooltip=["ë‚œì´ë„", "ì˜¤ë‹µìˆ˜"],
                    )
                    .properties(height=220)
                )
                st.altair_chart(diff_chart, use_container_width=True)
        st.markdown("---")

    # 2ë‹¨ ë ˆì´ì•„ì›ƒ
    col_left, col_right = st.columns([1, 1])
    
    with col_left:
        st.markdown("#### ğŸ“Š ì˜¤ë‹µ í‚¤ì›Œë“œ ë¶„ì„")
        keyword_df = top_keywords(incorrect["instruction"].tolist(), top_n=10)
        if keyword_df.empty:
            st.caption("ë¶„ì„ ê°€ëŠ¥í•œ í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            keyword_chart = (
                alt.Chart(keyword_df)
                .mark_bar(color="#f97316", cornerRadiusEnd=4)
                .encode(
                    x=alt.X("count:Q", title="ë¹ˆë„"),
                    y=alt.Y("keyword:N", sort="-x", title="í‚¤ì›Œë“œ"),
                    tooltip=[
                        alt.Tooltip("keyword:N", title="í‚¤ì›Œë“œ"),
                        alt.Tooltip("count:Q", title="ë¹ˆë„")
                    ],
                )
                .properties(height=300)
            )
            st.altair_chart(keyword_chart, width='stretch')
    
    with col_right:
        st.markdown("#### ğŸ“ˆ ì˜¤ë‹µ ë¶„í¬")
        if dataset == "cpa" and "subject" in incorrect.columns:
            subject_counts = incorrect["subject"].value_counts().reset_index()
            subject_counts.columns = ["ê³¼ëª©", "ì˜¤ë‹µìˆ˜"]
            subject_chart = (
                alt.Chart(subject_counts)
                .mark_arc(innerRadius=50)
                .encode(
                    theta=alt.Theta("ì˜¤ë‹µìˆ˜:Q"),
                    color=alt.Color("ê³¼ëª©:N", scale=alt.Scale(scheme="category10")),
                    tooltip=["ê³¼ëª©", "ì˜¤ë‹µìˆ˜"]
                )
                .properties(height=300)
            )
            st.altair_chart(subject_chart, width='stretch')
        elif "target_year" in incorrect.columns:
            year_counts = incorrect["target_year"].value_counts().reset_index()
            year_counts.columns = ["ì—°ë„", "ì˜¤ë‹µìˆ˜"]
            year_chart = (
                alt.Chart(year_counts)
                .mark_bar(color="#764ba2", cornerRadiusEnd=4)
                .encode(
                    x=alt.X("ì—°ë„:O", title="ì—°ë„"),
                    y=alt.Y("ì˜¤ë‹µìˆ˜:Q", title="ì˜¤ë‹µ ìˆ˜"),
                    tooltip=["ì—°ë„", "ì˜¤ë‹µìˆ˜"]
                )
                .properties(height=300)
            )
            st.altair_chart(year_chart, width='stretch')

    # ì˜¤ë‹µ ëª©ë¡
    st.markdown("#### ğŸ“ ì˜¤ë‹µ ëª©ë¡")
    
    id_col = "unique_id" if "unique_id" in incorrect.columns else "question_id"
    preview_cols = [id_col, "instruction", "ground_truth", "prediction", "prediction_1", "extracted_1", "Judge_Reason"]
    preview_cols = [c for c in preview_cols if c in incorrect.columns]
    preview_df = incorrect[preview_cols].copy()
    
    preview_df["ì •ë‹µ"] = preview_df["ground_truth"].apply(extract_final_answer)
    if "prediction" in preview_df.columns:
        preview_df["ëª¨ë¸ë‹µë³€"] = preview_df["prediction"].astype(str).str.strip()
    elif "prediction_1" in preview_df.columns:
        preview_df["ëª¨ë¸ë‹µë³€"] = preview_df["prediction_1"].apply(extract_final_answer)
    elif "extracted_1" in preview_df.columns:
        preview_df["ëª¨ë¸ë‹µë³€"] = preview_df["extracted_1"].astype(str).str.strip()
    else:
        preview_df["ëª¨ë¸ë‹µë³€"] = ""
    if "Judge_Reason" in incorrect.columns:
        preview_df["íŒë³„ ì´ìœ "] = incorrect["Judge_Reason"].astype(str).str.strip()
    if "correct_answer" in incorrect.columns:
        preview_df["ì •ë‹µë²ˆí˜¸"] = incorrect["correct_answer"]
    
    # í…ìŠ¤íŠ¸ ì¶•ì•½
    preview_df["ë¬¸ì œ"] = preview_df["instruction"].apply(lambda x: shorten(x, 100))
    
    # í‘œì‹œ ì»¬ëŸ¼: ë¬¸í•­, ë¬¸ì œ, ì •ë‹µ, ëª¨ë¸ë‹µë³€, íŒë³„ ì´ìœ (ì£¼ê´€ì‹)
    display_cols = [id_col, "ë¬¸ì œ", "ì •ë‹µ", "ëª¨ë¸ë‹µë³€"]
    if "ì •ë‹µë²ˆí˜¸" in preview_df.columns:
        display_cols.insert(2, "ì •ë‹µë²ˆí˜¸")
    if "íŒë³„ ì´ìœ " in preview_df.columns:
        display_cols.append("íŒë³„ ì´ìœ ")
    
    st.dataframe(
        preview_df[display_cols], 
        width='stretch', 
        height=350,
        hide_index=True
    )

    col_dl, col_space = st.columns([1, 3])
    with col_dl:
        st.download_button(
            "ğŸ“¥ ì˜¤ë‹µ CSV ë‹¤ìš´ë¡œë“œ",
            incorrect.to_csv(index=False).encode("utf-8"),
            file_name=f"{model_choice.replace('/', '_')}_errors_pass{pass_k}.csv",
            mime="text/csv",
        )

    # ì˜¤ë‹µ ìƒì„¸ ë³´ê¸°
    with st.expander("ğŸ” ì˜¤ë‹µ ìƒì„¸ ë³´ê¸°"):
        selection_labels = [
            f"{row[id_col]} | {shorten(row['instruction'], 70)}"
            for _, row in incorrect.iterrows()
        ]
        selected_label = st.selectbox("ë¬¸í•­ ì„ íƒ", selection_labels, key="detail_select")
        selected_idx = selection_labels.index(selected_label)
        row = incorrect.iloc[selected_idx]

        st.markdown("**ğŸ“‹ ë¬¸ì œ**")
        st.info(row.get("instruction", ""))
        
        st.markdown("**âœ… ì •ë‹µ**")
        st.success(row.get("ground_truth", ""))

        extra_fields = []
        if dataset == "cpa":
            for field in ["year", "subject", "question_number", "correct_answer"]:
                if field in row and pd.notna(row[field]):
                    extra_fields.append(f"**{field}**: {row[field]}")
        if "target_year" in row and pd.notna(row.get("target_year")):
            extra_fields.append(f"**ì—°ë„**: {row['target_year']}")
        if extra_fields:
            st.markdown(" | ".join(extra_fields))

        # ì£¼ê´€ì‹: ëª¨ë¸ ë‹µë³€(prediction) + Judge íŒë³„ ì´ìœ 
        if "prediction" in row.index and pd.notna(row.get("prediction")) and str(row.get("prediction", "")).strip():
            st.markdown("**ğŸ¤– ëª¨ë¸ ë‹µë³€**")
            st.write(str(row["prediction"]).strip())
        if "Judge_Reason" in row.index and pd.notna(row.get("Judge_Reason")) and str(row.get("Judge_Reason", "")).strip():
            st.markdown("**âš–ï¸ Judge íŒë³„ ì´ìœ **")
            st.info(str(row["Judge_Reason"]).strip())
        if "Judge_Score" in row.index and pd.notna(row.get("Judge_Score")):
            st.caption(f"Judge_Score: {row['Judge_Score']}")

        st.markdown("**ğŸ¤– ëª¨ë¸ ì‘ë‹µ** (ìƒ˜í”Œë³„)")
        for i in range(1, 6):
            col = f"prediction_{i}"
            ext_col = f"extracted_{i}"
            if col in row and pd.notna(row[col]):
                final_ans = extract_final_answer(row[col])
                with st.expander(f"ìƒ˜í”Œ {i}: {final_ans}"):
                    st.write(row[col])
            elif ext_col in row and pd.notna(row[ext_col]):
                with st.expander(f"ìƒ˜í”Œ {i}: {row[ext_col]}"):
                    st.write(f"ì¶”ì¶œ ë‹µ: {row[ext_col]}")

        matches = matching_samples(row, pass_k)
        if matches:
            st.success(f"âœ“ Pass@{pass_k} ë§¤ì¹­ ìƒ˜í”Œ: {matches}")


def render_analysis_section(df: pd.DataFrame, pass_k: int, bench_main: str):
    """ìƒì„¸ ë¶„ì„ í˜ì´ì§€"""
    if df.empty:
        st.info("ë¶„ì„ì— í•„ìš”í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    pass_col = f"pass_at_{pass_k}"
    if pass_col not in df.columns:
        st.info("Pass@k ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    st.markdown("### ğŸ“ˆ ì„±ëŠ¥ ë¶„ì„")

    # ëª¨ë¸ë³„ ì„ íƒ: ì„ íƒ ì‹œ í•´ë‹¹ ëª¨ë¸ë§Œ ìƒì„¸ ë¶„ì„ë€ì— ë°˜ì˜
    model_list = sorted(df["model"].dropna().unique().tolist())
    options = ["ì „ì²´ (ëª¨ë¸ ë¹„êµ)"] + model_list
    model_choice = st.selectbox(
        "ë¶„ì„í•  ëª¨ë¸",
        options,
        index=0,
        format_func=lambda x: x if x == "ì „ì²´ (ëª¨ë¸ ë¹„êµ)" else (x.split("/")[-1] if "/" in str(x) else x),
        key="analysis_model_select",
    )
    if model_choice == "ì „ì²´ (ëª¨ë¸ ë¹„êµ)":
        df_analysis = df
    else:
        df_analysis = df[df["model"] == model_choice].copy()
        if df_analysis.empty:
            st.warning("ì„ íƒí•œ ëª¨ë¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        st.caption(f"ì„ íƒ ëª¨ë¸: **{model_choice}** ({len(df_analysis):,}ë¬¸í•­)")

    # 2ë‹¨ ë ˆì´ì•„ì›ƒ
    col_left, col_right = st.columns(2)
    
    with col_left:
        if bench_main == "CPA" and "year" in df_analysis.columns:
            st.markdown("#### ì—°ë„ë³„ í‰ê·  ì •í™•ë„")
            year_trend = (
                df_analysis.groupby("year", dropna=False)[pass_col]
                .mean()
                .reset_index()
                .assign(accuracy=lambda d: d[pass_col] * 100)
            )
            year_chart = (
                alt.Chart(year_trend)
                .mark_bar(cornerRadiusTopLeft=6, cornerRadiusTopRight=6, color="#667eea")
                .encode(
                    x=alt.X("year:O", title="ì—°ë„"),
                    y=alt.Y("accuracy:Q", title="ì •í™•ë„ (%)", scale=alt.Scale(domain=[0, 100])),
                    tooltip=[
                        alt.Tooltip("year:O", title="ì—°ë„"),
                        alt.Tooltip("accuracy:Q", format=".1f", title="ì •í™•ë„(%)")
                    ],
                )
                .properties(height=280)
            )
            st.altair_chart(year_chart, width='stretch')
        elif bench_main == "ê°œì •ì„¸ë²•" and "target_year" in df_analysis.columns:
            st.markdown("#### ì—°ë„ë³„ í‰ê·  ì •í™•ë„")
            year_trend = (
                df_analysis.groupby("target_year", dropna=False)[pass_col]
                .mean()
                .reset_index()
                .assign(accuracy=lambda d: d[pass_col] * 100)
            )
            year_chart = (
                alt.Chart(year_trend)
                .mark_bar(cornerRadiusTopLeft=6, cornerRadiusTopRight=6, color="#764ba2")
                .encode(
                    x=alt.X("target_year:O", title="ì—°ë„"),
                    y=alt.Y("accuracy:Q", title="ì •í™•ë„ (%)", scale=alt.Scale(domain=[0, 100])),
                    tooltip=[
                        alt.Tooltip("target_year:O", title="ì—°ë„"),
                        alt.Tooltip("accuracy:Q", format=".1f", title="ì •í™•ë„(%)")
                    ],
                )
                .properties(height=280)
            )
            st.altair_chart(year_chart, width='stretch')
    
    with col_right:
        st.markdown("#### íŒŒë¼ë¯¸í„° ìˆ˜ vs ì •í™•ë„")
        leaderboard = build_leaderboard(df, pass_k)
        scatter_df = leaderboard.dropna(subset=["params_b"])
        if scatter_df.empty:
            st.caption("íŒŒë¼ë¯¸í„° ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
        else:
            scatter = (
                alt.Chart(scatter_df)
                .mark_circle(size=120, opacity=0.7)
                .encode(
                    x=alt.X("params_b:Q", title="íŒŒë¼ë¯¸í„° ìˆ˜ (B)", scale=alt.Scale(type="log")),
                    y=alt.Y("pass_rate:Q", title="ì •í™•ë„ (%)"),
                    color=alt.Color("organization:N", legend=alt.Legend(title="í”Œë«í¼")),
                    tooltip=[
                        alt.Tooltip("display_model:N", title="ëª¨ë¸"),
                        alt.Tooltip("params_b:Q", format=".1f", title="íŒŒë¼ë¯¸í„°(B)"),
                        alt.Tooltip("pass_rate:Q", format=".2f", title="ì •í™•ë„(%)"),
                    ],
                )
                .properties(height=280)
            )
            st.altair_chart(scatter, width='stretch')

    # ëª¨ë¸ë³„ ìƒì„¸ ì¶”ì´ (ê°œì •ì„¸ë²•ì˜ ê²½ìš°) â€” ì„ íƒ ëª¨ë¸ì´ ìˆìœ¼ë©´ í•´ë‹¹ ëª¨ë¸ë§Œ í‘œì‹œ
    if bench_main == "ê°œì •ì„¸ë²•" and "target_year" in df_analysis.columns:
        st.markdown("#### ì—°ë„ë³„ ì¶”ì´")
        trend = (
            df_analysis.groupby(["target_year", "model"], dropna=False)[pass_col]
            .mean()
            .reset_index()
            .assign(accuracy=lambda d: d[pass_col] * 100)
        )
        trend["model_short"] = trend["model"].apply(lambda x: x.split('/')[-1][:30] if isinstance(x, str) else x)
        
        line = (
            alt.Chart(trend)
            .mark_line(point=True, strokeWidth=2)
            .encode(
                x=alt.X("target_year:O", title="ì—°ë„"),
                y=alt.Y("accuracy:Q", title="ì •í™•ë„ (%)"),
                color=alt.Color("model_short:N", legend=alt.Legend(title="ëª¨ë¸", labelLimit=200)),
                tooltip=[
                    alt.Tooltip("model_short:N", title="ëª¨ë¸"),
                    alt.Tooltip("target_year:O", title="ì—°ë„"),
                    alt.Tooltip("accuracy:Q", format=".1f", title="ì •í™•ë„(%)")
                ],
            )
            .properties(height=350)
        )
        st.altair_chart(line, width='stretch')
    
    # CPA ê³¼ëª©ë³„ ë¶„ì„ â€” ì„¸ë¡œ ë§‰ëŒ€(ê°€ë…ì„±)
    elif bench_main == "CPA" and "subject" in df_analysis.columns:
        st.markdown("#### ê³¼ëª©ë³„ ì„±ëŠ¥ ë¹„êµ")
        subject_perf = (
            df_analysis.groupby("subject", dropna=False)[pass_col]
            .mean()
            .reset_index()
            .assign(accuracy=lambda d: d[pass_col] * 100)
            .sort_values("accuracy", ascending=False)
        )
        # ë„í‘œ ìœ„ì— ê³¼ëª©ë³„ ì ìˆ˜ ë°”ë¡œ í‘œì‹œ
        n_subj = len(subject_perf)
        score_cols = st.columns(max(1, n_subj))
        for i, (_, row) in enumerate(subject_perf.iterrows()):
            with score_cols[i]:
                st.metric(label=row["subject"], value=f"{row['accuracy']:.1f}%")
        subject_chart = (
            alt.Chart(subject_perf)
            .mark_bar(cornerRadiusTopLeft=6, cornerRadiusTopRight=6)
            .encode(
                x=alt.X(
                    "subject:N",
                    sort="-y",
                    title="ê³¼ëª©",
                    axis=alt.Axis(labelAngle=-25, labelLimit=120),
                ),
                y=alt.Y(
                    "accuracy:Q",
                    title="ì •í™•ë„ (%)",
                    scale=alt.Scale(domain=[0, 100]),
                ),
                color=alt.Color("subject:N", legend=None, scale=alt.Scale(scheme="category10")),
                tooltip=[
                    alt.Tooltip("subject:N", title="ê³¼ëª©"),
                    alt.Tooltip("accuracy:Q", format=".1f", title="ì •í™•ë„(%)"),
                ],
            )
            .properties(height=320)
        )
        st.altair_chart(subject_chart, width='stretch')


def render_model_cards(metadata: dict):
    models = metadata.get("models", [])
    if not models:
        st.info("ëª¨ë¸ ë©”íƒ€ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    meta_df = pd.DataFrame(models)
    st.dataframe(meta_df, width='stretch')


def render_data_and_eval_page():
    """ë°ì´í„° êµ¬ì„±Â·ì˜ˆì‹œÂ·íŒë³„ ë°©ì‹ì„ í•œ í˜ì´ì§€ë¡œ ì•ˆë‚´"""
    st.markdown("### ğŸ“„ ë°ì´í„° ë° í‰ê°€ ë°©ì‹ ì•ˆë‚´")

    st.markdown("---")
    st.markdown("#### 1. ë°ì´í„° êµ¬ì„± (ì–´ë–¤ ì‹ìœ¼ë¡œ ë§Œë“¤ì—ˆëŠ”ì§€)")

    st.markdown("""
| ë²¤ì¹˜ë§ˆí¬ | ë°ì´í„° ì¶œì²˜ | êµ¬ì„± ë°©ì‹ |
|----------|-------------|-----------|
| **CPA ì¢…í•©** | ê³µì¸íšŒê³„ì‚¬ ì‹œí—˜ ê¸°ì¶œ (2016~2025) | ë¬¸í•­ë³„ user/assistant ëŒ€í™”í˜• QA. ê³¼ëª©(ì„¸ë²•, íšŒê³„í•™, ê²½ì˜í•™ ë“±)Â·ì—°ë„Â·ë¬¸í•­ë²ˆí˜¸ ë©”íƒ€ë°ì´í„° í¬í•¨. |
| **ê°œì •ì„¸ë²• ê°ê´€ì‹** | ì—°ë„ë³„ ê°œì •ì„¸ë²• í•´ì„¤ ê¸°ë°˜ | 2023Â·2024Â·2025ë…„ ê°œì •ì„¸ë²• ê¸°ì¤€ 4ì§€ì„ ë‹¤(500ë¬¸í•­/ì—°ë„). instruction + choices(A/B/C/D) + ì •ë‹µ. GPTë¡œ ë¬¸í•­ ìƒì„±Â·ì •ë‹µ ë¼ë²¨ ë¶€ì—¬. |
| **ê°œì •ì„¸ë²• ì£¼ê´€ì‹** (ì˜µì…˜) | ì—°ë„ë³„ ì„¸ë²• QA | 2021Â·2022Â·2023Â·2025 ì—°ë„ë³„ ì£¼ê´€ì‹ QA. ì¶”ë¡  í›„ **Judge API**ë¡œ Pass/Fail ì±„ì ëœ ê²°ê³¼ë§Œ ë¦¬ë”ë³´ë“œì— ë°˜ì˜. |
""")

    st.markdown("---")
    st.markdown("#### 2. ë°ì´í„° ì˜ˆì‹œ")

    st.markdown("**CPA (ëŒ€í™”í˜•)**")
    st.code("""{
  "conversation": [
    {"role": "user", "content": "ë‹¤ìŒ ë¬¸ì œë¥¼ í’€ì–´ì£¼ì„¸ìš”: ..."},
    {"role": "assistant", "content": "ì •ë‹µ: â‘¢"}
  ],
  "metadata": {"year": 2023, "subject": "ì„¸ë²•", "question_number": 1}
}""", language="json")

    st.markdown("**ê°œì •ì„¸ë²• ê°ê´€ì‹ (4ì§€ì„ ë‹¤)**")
    st.code("""{
  "instruction": "2023ë…„ ê°œì •ì„¸ë²• ê¸°ì¤€: ë‹¤ìŒ ì¤‘ ... ì˜³ì€ ê²ƒì€?",
  "context": "êµ­ì„¸ê¸°ë³¸ë²• (ì°¨ë¡€ ê¸°ë°˜)",
  "choices": {"A": "...", "B": "...", "C": "...", "D": "..."},
  "answer": "C",
  "difficulty": "easy"
}""", language="json")

    st.markdown("---")
    st.markdown("#### 3. íŒë³„ ë°©ì‹")

    st.markdown("""
- **Pass@k**: ë¬¸í•­ë‹¹ kê°œ ë‹µë³€ ìƒì„± í›„, **í•˜ë‚˜ë¼ë„ ì •ë‹µì´ë©´** í•´ë‹¹ ë¬¸í•­ ì •ë‹µ ì²˜ë¦¬. (k=1, 3, 5 ì¤‘ ì„ íƒ)
- **CPA**: ëª¨ë¸ ì¶œë ¥ì—ì„œ `ìµœì¢…ì •ë‹µ:` / `ì •ë‹µ:` ë’¤ ë¬¸ìÂ·ë²ˆí˜¸(â‘ â‘¡â‘¢ ë˜ëŠ” 1~5) ì¶”ì¶œ â†’ ì •ë‹µ ë¼ë²¨ê³¼ **ë¬¸ì/ë²ˆí˜¸ ì •ê·œí™” í›„ ë¹„êµ**.
- **ê°œì •ì„¸ë²• ê°ê´€ì‹**: ì¶œë ¥ì—ì„œ A/B/C/D ì¶”ì¶œ(ì •ë‹µ: A, (B), ë¬¸ì¥ ë‚´ ì²« A~D ë“±) â†’ **ì •ë‹µ ë¬¸ìì™€ ëŒ€ì†Œë¬¸ì ë¬´ì‹œ ë¹„êµ**.
- **ê°œì •ì„¸ë²• ì£¼ê´€ì‹**: **Judge API**ë¡œ (instruction, ground_truth, prediction) ì „ë‹¬ í›„ Pass/Fail íŒì •. ë¦¬ë”ë³´ë“œëŠ” evaluated CSVì˜ Judge_Scoreë§Œ ì‚¬ìš©(ë¬¸ìì—´ ì§ì ‘ ë¹„êµ ì—†ìŒ).
- **ì „ì²´ ëª¨ë¸ ì„±ëŠ¥ ì¢…í•©**: CPA 1.0ë°° + ê°œì •ì„¸ë²• ê°ê´€ì‹ 0.6ë°°(ê³ ì •). ì˜µì…˜ìœ¼ë¡œ ì£¼ê´€ì‹ í¬í•¨ ì‹œ ì£¼ê´€ì‹ 1.0ë°° ì¶”ê°€. ì—†ìœ¼ë©´ 0ì ìœ¼ë¡œ í¬í•¨í•´ ê°€ì¤‘ í‰ê· .
""")

    st.markdown("---")
    st.caption("ë¦¬ë”ë³´ë“œ ë°ì´í„°Â·í‰ê°€ ë°©ì‹ ìš”ì•½. ìƒì„¸ ìŠ¤í¬ë¦½íŠ¸ëŠ” docs/ ë° results_* í´ë” ì°¸ê³ .")


def main():
    st.set_page_config(
        page_title=APP_TITLE, 
        layout="wide",
        page_icon="ğŸ›ï¸",
        initial_sidebar_state="collapsed"
    )
    render_header()

    data_root = find_data_root()
    metadata = load_metadata(str(data_root))

    # ìƒë‹¨ í•„í„°
    render_aihub_shell()

    col1, col2 = st.columns([1, 1])
    with col1:
        pass_k = st.selectbox("ğŸ“ˆ í‰ê°€ì§€í‘œ", PASS_K_OPTIONS, index=2, format_func=pass_label)
    with col2:
        korean_only = st.checkbox("í•œêµ­ì–´ ì‚¬ì „í•™ìŠµ", value=False)

    # ë°ì´í„° ë¡œë“œ
    yearly_all = load_yearly(str(data_root))
    yearly_all = attach_metadata(yearly_all, metadata)
    if "target_year" not in yearly_all.columns and "year_from_file" in yearly_all.columns:
        yearly_all["target_year"] = yearly_all["year_from_file"]

    cpa_all = load_cpa(str(data_root))
    cpa_all = attach_metadata(cpa_all, metadata)

    tax500_all = load_tax500(str(data_root))
    tax500_all = attach_metadata(tax500_all, metadata)

    # ê³ ê¸‰ í•„í„°
    with st.expander("ğŸ”§ ê³ ê¸‰ í•„í„°"):
        filter_cols = st.columns(3)

        with filter_cols[0]:
            combined_meta = pd.concat(
                [yearly_all, cpa_all, tax500_all], ignore_index=True
            )
            orgs = sorted(combined_meta["organization"].dropna().unique().tolist())
            org_filter = st.multiselect("ì œì¶œ í”Œë«í¼", orgs)
            include_yearly_tax = st.checkbox(
                "ë¦¬ë”ë³´ë“œì— ê°œì •ì„¸ë²•(ì£¼ê´€ì‹Â·ì—°ë„ë³„) í¬í•¨",
                value=False,
                key="include_yearly_tax",
                help="ì²´í¬ ì‹œ ì „ì²´ ëª¨ë¸ ì„±ëŠ¥ ì¢…í•©Â·í…Œì´ë¸”Â·ì°¨íŠ¸ì— ê°œì •ì„¸ë²• ì—°ë„ë³„ QAê°€ í¬í•¨ë©ë‹ˆë‹¤.",
            )

        with filter_cols[1]:
            years_yearly = sorted(yearly_all["target_year"].dropna().unique().tolist())
            years_tax500 = sorted(
                tax500_all["target_year"].dropna().unique().tolist()
            )
            years_cpa = sorted(cpa_all["year"].dropna().unique().tolist())
            subjects_cpa = sorted(cpa_all["subject"].dropna().unique().tolist())
            yearly_filter = st.multiselect("ê°œì •ì„¸ë²• ì—°ë„", years_yearly, default=years_yearly)
            tax500_year_filter = st.multiselect(
                "ê°œì •ì„¸ë²• ê°ê´€ì‹ ì—°ë„", years_tax500, default=years_tax500
            )
            cpa_year_filter = st.multiselect("CPA ì—°ë„", years_cpa, default=years_cpa)
            cpa_subject_filter = st.multiselect("CPA ê³¼ëª©", subjects_cpa, default=subjects_cpa)

        with filter_cols[2]:
            model_list = sorted(combined_meta["model"].dropna().unique().tolist())
            model_filter = st.multiselect(
                "ëª¨ë¸ ì„ íƒ",
                model_list,
                format_func=lambda x: x.split('/')[-1] if '/' in x else x
            )

    def apply_meta_filters(frame: pd.DataFrame) -> pd.DataFrame:
        if frame.empty:
            return frame
        if korean_only:
            frame = frame[frame["korean_pretrained"] == True]
        if org_filter:
            frame = frame[frame["organization"].isin(org_filter)]
        if model_filter:
            frame = frame[frame["model"].isin(model_filter)]
        return frame

    yearly_filtered = yearly_all.copy()
    cpa_filtered = cpa_all.copy()
    tax500_filtered = tax500_all.copy()

    if yearly_filter:
        yearly_filtered = yearly_filtered[
            yearly_filtered["target_year"].isin(yearly_filter)
        ]
    if tax500_year_filter:
        tax500_filtered = tax500_filtered[
            tax500_filtered["target_year"].isin(tax500_year_filter)
        ]
    if cpa_year_filter:
        cpa_filtered = cpa_filtered[cpa_filtered["year"].isin(cpa_year_filter)]
    if cpa_subject_filter:
        cpa_filtered = cpa_filtered[cpa_filtered["subject"].isin(cpa_subject_filter)]

    yearly_filtered = apply_meta_filters(yearly_filtered)
    cpa_filtered = apply_meta_filters(cpa_filtered)
    tax500_filtered = apply_meta_filters(tax500_filtered)

    if (
        yearly_filtered.empty
        and cpa_filtered.empty
        and tax500_filtered.empty
    ):
        st.warning("âš ï¸ í•„í„° ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì¡°ì •í•´ì£¼ì„¸ìš”.")
        return

    # íƒ­ êµ¬ì„±
    tab1, tab2, tab3, tab4 = st.tabs(
        ["ğŸ“Š ë¦¬ë”ë³´ë“œ", "ğŸ” ì˜¤ë‹µ ë¶„ì„", "ğŸ“ˆ ìƒì„¸ ë¶„ì„", "ğŸ“„ ë°ì´í„°Â·í‰ê°€ ì•ˆë‚´"]
    )

    with tab1:
        render_leaderboard_section(
            yearly_filtered,
            cpa_filtered,
            tax500_filtered,
            pass_k,
            metadata,
            include_yearly_tax=include_yearly_tax,
        )

    with tab2:
        err_ds = st.selectbox(
            "ì˜¤ë‹µ ë¶„ì„ ë°ì´í„°",
            ["CPA", "ê°œì •ì„¸ë²•(ì—°ë„ë³„)", "ê°œì •ì„¸ë²• ê°ê´€ì‹"],
            key="err_ds",
        )
        if err_ds == "CPA":
            df_err = cpa_filtered
            render_error_section(df_err, pass_k, "cpa")
        elif err_ds == "ê°œì •ì„¸ë²• ê°ê´€ì‹":
            df_err = tax500_filtered
            render_error_section(df_err, pass_k, "yearly")
        else:
            df_err = yearly_filtered
            render_error_section(df_err, pass_k, "yearly")

    with tab3:
        ana_ds = st.selectbox(
            "ë¶„ì„ ë°ì´í„°",
            ["CPA", "ê°œì •ì„¸ë²•(ì—°ë„ë³„)", "ê°œì •ì„¸ë²• ê°ê´€ì‹"],
            key="ana_ds",
        )
        if ana_ds == "CPA":
            df_ana = cpa_filtered
            render_analysis_section(df_ana, pass_k, "CPA")
        elif ana_ds == "ê°œì •ì„¸ë²• ê°ê´€ì‹":
            df_ana = tax500_filtered
            render_analysis_section(df_ana, pass_k, "ê°œì •ì„¸ë²•")
        else:
            df_ana = yearly_filtered
            render_analysis_section(df_ana, pass_k, "ê°œì •ì„¸ë²•")

    with tab4:
        render_data_and_eval_page()


if __name__ == "__main__":
    main()
